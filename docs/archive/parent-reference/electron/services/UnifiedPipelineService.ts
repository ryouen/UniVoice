/**
 * UnifiedPipelineService.ts
 * 
 * test-20min-production-detailed.jsã®å‡¦ç†ã‚’
 * ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã§å®Ÿè£…
 * 
 * 8ãƒ–ãƒ­ãƒƒã‚¯UIæ§‹æˆ:
 * â‘ â‘¡ History (English/Japanese) - å®Œäº†ã—ãŸç¿»è¨³å±¥æ­´
 * â‘¢â‘£ Current (English/Japanese) - ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç¿»è¨³
 * â‘¤â‘¥ Summary (English/Japanese) - Progressiveè¦ç´„
 * â‘¦â‘§ User    (Input/Translation) - ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ç¿»è¨³
 */

import { EventEmitter } from 'events';
import { WebSocket } from 'ws';
import OpenAI from 'openai';
import { app } from 'electron';
import * as fs from 'fs';
import * as path from 'path';

// ===== å‹å®šç¾© =====
interface AudioConfig {
  frameMs: number;
  frameSize: number;
  sampleRate: number;
}

interface DeepgramConfig {
  apiKey: string;
  model: string;
  interim: boolean;
  endpointing: number;
  utteranceEndMs: number;
}

interface OpenAIConfig {
  apiKey: string;
  models: {
    translate: string;     // â‘¡ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç¿»è¨³: gpt-5-nano
    summary: string;       // â‘¢å®šæœŸè¦ç´„: gpt-5-mini
    summaryTranslate: string; // â‘£è¦ç´„ç¿»è¨³: gpt-5-nano
    userTranslate: string; // â‘£ãƒ¦ãƒ¼ã‚¶ãƒ¼ç¿»è¨³: gpt-5-nano
    vocabulary: string;    // â‘¤å˜èªå¸³: gpt-5-mini
    report: string;        // â‘¥æœ€çµ‚ãƒ¬ãƒãƒ¼ãƒˆ: gpt-5
  };
  maxTokens: {
    translate: number;
    summary: number;
    vocabulary: number;
    report: number;
  };
}

interface TranscriptSegment {
  id: string;
  text: string;
  timestamp: number;
  confidence: number;
  isFinal: boolean;
}

interface Translation {
  id: string;
  original: string;
  japanese: string;
  timestamp: number;
  firstPaintMs: number;
  completeMs: number;
}

interface Summary {
  id: string;
  english: string;
  japanese: string;
  wordCount: number;
  timestamp: number;
  timeRange: {
    start: number;
    end: number;
  };
}

interface VocabularyEntry {
  word: string;
  definition: string;
  example?: string;
}

// ===== ãƒ¡ã‚¤ãƒ³ã‚µãƒ¼ãƒ“ã‚¹ =====
export class UnifiedPipelineService extends EventEmitter {
  // è¨­å®š
  private audioConfig: AudioConfig;
  private deepgramConfig: DeepgramConfig;
  private openaiConfig: OpenAIConfig;
  
  // æ¥ç¶š
  private ws: WebSocket | null = null;
  private openai: OpenAI;
  
  // çŠ¶æ…‹
  private isRunning = false;
  private audioBuffer: Buffer | null = null;
  private frameIndex = 0;
  private frameTimer: NodeJS.Timeout | null = null;
  
  // ãƒ‡ãƒ¼ã‚¿ã‚¹ãƒˆã‚¢ï¼ˆ8ãƒ–ãƒ­ãƒƒã‚¯å¯¾å¿œï¼‰
  private currentOriginal = '';      // â‘¢Current English
  private currentTranslation = '';   // â‘£Current Japanese
  private history: Translation[] = []; // â‘ â‘¡History
  private summaries: Summary[] = [];   // â‘¤â‘¥Summary
  private vocabulary: VocabularyEntry[] = []; // èªå½™
  
  // Progressive Summarization
  private summaryBuffer: string[] = [];
  private summaryWordCount = 0;
  private summaryThresholds = [400, 800, 1600]; // æ®µéšçš„è¦ç´„
  private currentThresholdIndex = 0;
  
  // ç¿»è¨³ã‚­ãƒ¥ãƒ¼
  private translationQueue: Array<() => Promise<void>> = [];
  private activeTranslations = 0;
  private maxConcurrency = 3;
  private lastInterimText = '';
  private lastInterimTime = 0;
  
  constructor(
    audioConfig: AudioConfig,
    deepgramConfig: DeepgramConfig,
    openaiConfig: OpenAIConfig
  ) {
    super();
    
    this.audioConfig = audioConfig;
    this.deepgramConfig = deepgramConfig;
    this.openaiConfig = openaiConfig;
    
    this.openai = new OpenAI({
      apiKey: openaiConfig.apiKey,
      dangerouslyAllowBrowser: false
    });
  }
  
  // ===== ãƒ‘ãƒ–ãƒªãƒƒã‚¯API =====
  
  async startFromFile(audioPath: string): Promise<void> {
    if (this.isRunning) await this.stop();
    console.log(`[UnifiedPipeline] Starting from file: ${audioPath}`);

    // âœ… ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’å …ç‰¢ã«è§£æ±º
    const candidates: string[] = [];
    if (path.isAbsolute(audioPath)) {
      candidates.push(audioPath);
    } else {
      candidates.push(
        path.resolve(process.cwd(), audioPath),
        path.resolve(process.cwd(), 'sample_voice', audioPath),
        path.resolve(app.getAppPath(), audioPath),
        path.resolve(app.getAppPath(), 'sample_voice', audioPath),
        path.resolve(__dirname, '..', '..', 'sample_voice', audioPath) // disté…ç½®æƒ³å®š
      );
    }
    const resolvedPath = candidates.find(p => fs.existsSync(p));
    if (!resolvedPath) {
      throw new Error(`Audio file not found. Tried:\n${candidates.join('\n')}`);
    }
    console.log(`[UnifiedPipeline] Resolved path: ${resolvedPath}`);

    // WAVæƒ³å®šï¼šå…ˆé ­44byteãƒ˜ãƒƒãƒ€ã‚’ã‚¹ã‚­ãƒƒãƒ—ã— raw PCM16 (16k) ã‚’é€ã‚‹
    const audioData = fs.readFileSync(resolvedPath);
    this.audioBuffer = audioData.slice(44);

    await this.start(); // Deepgramæ¥ç¶šâ†’ãƒ•ã‚¡ã‚¤ãƒ«é€å‡º
  }
  
  async startFromMicrophone(): Promise<void> {
    if (this.isRunning) await this.stop();

    console.log('[UnifiedPipeline] Starting from microphone');
    this.audioBuffer = null;          // ãƒã‚¤ã‚¯ã¯ push å‹
    this.frameIndex = 0;

    await this.start();               // Deepgramæ¥ç¶šã®ã¿ï¼ˆé€å‡ºã¯ sendAudioChunk ã§ï¼‰
    // Renderer ãŒ window.electron.sendAudioChunk() ã§ãƒ—ãƒƒã‚·ãƒ¥ã—ã¦ãã‚‹æƒ³å®š
  }
  
  /** Deepgram æ¥ç¶šâ†’ãƒ•ã‚¡ã‚¤ãƒ«ãªã‚‰é€å‡ºé–‹å§‹ */
  private async start(): Promise<void> {
    this.isRunning = true;
    await this.connectDeepgram();
    if (this.audioBuffer) this.startAudioStreaming(); // ãƒ•ã‚¡ã‚¤ãƒ«æ™‚ã®ã¿
    this.emit('started');
  }
  
  async stop(): Promise<void> {
    if (!this.isRunning) return;
    
    this.isRunning = false;
    
    // ã‚¿ã‚¤ãƒãƒ¼åœæ­¢
    if (this.frameTimer) {
      clearInterval(this.frameTimer);
      this.frameTimer = null;
    }
    
    // WebSocketçµ‚äº†
    if (this.ws) {
      this.ws.send(JSON.stringify({ type: 'Finalize' }));
      this.ws.send(JSON.stringify({ type: 'CloseStream' }));
      this.ws.close();
      this.ws = null;
    }
    
    // æœ€çµ‚ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
    if (this.history.length > 0) {
      await this.generateFinalReport();
    }
    
    this.emit('stopped');
  }
  
  // ===== â‘ éŸ³å£°å…¥åŠ› =====
  
  private startAudioStreaming(): void {
    if (!this.audioBuffer) return;
    
    const totalFrames = Math.floor(this.audioBuffer.length / this.audioConfig.frameSize);
    this.frameIndex = 0;
    
    this.frameTimer = setInterval(() => {
      if (!this.isRunning || this.frameIndex >= totalFrames) {
        if (this.frameTimer) {
          clearInterval(this.frameTimer);
          this.frameTimer = null;
        }
        return;
      }
      
      const frame = this.audioBuffer!.slice(
        this.frameIndex * this.audioConfig.frameSize,
        (this.frameIndex + 1) * this.audioConfig.frameSize
      );
      
      if (this.ws && this.ws.readyState === WebSocket.OPEN) {
        this.ws.send(frame);
      }
      
      this.frameIndex++;
      
      // Progress event
      if (this.frameIndex % 50 === 0) {
        this.emit('audioProgress', {
          current: this.frameIndex,
          total: totalFrames,
          percentage: (this.frameIndex / totalFrames) * 100
        });
      }
    }, this.audioConfig.frameMs);
  }
  
  // ===== â‘¡ASRï¼ˆéŸ³å£°èªè­˜ï¼‰ =====
  
  private async connectDeepgram(): Promise<void> {
    const params = new URLSearchParams({
      encoding: 'linear16',
      sample_rate: this.audioConfig.sampleRate.toString(),
      interim_results: this.deepgramConfig.interim.toString(),
      endpointing: this.deepgramConfig.endpointing.toString(),
      utterance_end_ms: this.deepgramConfig.utteranceEndMs.toString(),
      punctuate: 'true',
      model: this.deepgramConfig.model
    });
    
    const url = `wss://api.deepgram.com/v1/listen?${params}`;
    
    this.ws = new WebSocket(url, {
      headers: {
        Authorization: `Token ${this.deepgramConfig.apiKey}`
      }
    });
    
    this.ws.on('open', () => {
      console.log('[UnifiedPipeline] Deepgram connected');
      this.emit('deepgramConnected');
    });
    
    this.ws.on('message', (data: Buffer) => {
      try {
        const msg = JSON.parse(data.toString());
        this.handleDeepgramMessage(msg);
      } catch (error) {
        console.error('[UnifiedPipeline] Parse error:', error);
      }
    });
    
    this.ws.on('error', (error) => {
      console.error('[UnifiedPipeline] WebSocket error:', error);
      this.emit('error', { stage: 'deepgram', error });
    });
  }
  
  private handleDeepgramMessage(msg: any): void {
    if (msg.type !== 'Results') return;
    
    const alternatives = msg.channel?.alternatives?.[0];
    if (!alternatives?.transcript) return;
    
    const segment: TranscriptSegment = {
      id: `seg_${Date.now()}`,
      text: alternatives.transcript,
      timestamp: Date.now(),
      confidence: alternatives.confidence || 0,
      isFinal: msg.is_final || false
    };
    
    // éŸ³å£°èªè­˜ãƒ­ã‚°
    console.log(`[Deepgram] ${segment.isFinal ? 'Final' : 'Interim'}: "${segment.text}" (confidence: ${segment.confidence.toFixed(2)})`);
    
    // â‘¢Current Englishæ›´æ–°ï¼ˆä¸­é–“çµæœã‚‚æœ€çµ‚çµæœã‚‚ä¸¡æ–¹è¡¨ç¤ºï¼‰
    this.currentOriginal = segment.text;
    this.emit('currentOriginalUpdate', {
      text: this.currentOriginal,
      isFinal: segment.isFinal
    });
    
    // ç¿»è¨³ãƒªã‚¯ã‚¨ã‚¹ãƒˆï¼ˆæ¡ä»¶ä»˜ãï¼‰
    if (segment.isFinal) {
      // æœ€çµ‚çµæœã¯å¿…ãšç¿»è¨³
      this.enqueueTranslation(segment);
      // æœ€çµ‚çµæœã®å¾Œã¯currentã‚’ã‚¯ãƒªã‚¢
      setTimeout(() => {
        this.currentOriginal = '';
        this.currentTranslation = '';
        this.emit('currentOriginalUpdate', {
          text: '',
          isFinal: true
        });
        this.emit('currentTranslationUpdate', '');
      }, 100);
    } else {
      // ä¸­é–“çµæœã®ç¿»è¨³æ¡ä»¶ã‚’ç·©å’Œ
      const shouldTranslate = 
        segment.text.length > 15 && // 15æ–‡å­—ä»¥ä¸Šï¼ˆã‚ˆã‚Šæ—©ãç¿»è¨³é–‹å§‹ï¼‰
        (!this.lastInterimText || // åˆå›
         segment.text.length > this.lastInterimText.length + 5 || // 5æ–‡å­—ä»¥ä¸Šå¢—åŠ 
         Date.now() - this.lastInterimTime > 500); // 500msä»¥ä¸ŠçµŒé
      
      if (shouldTranslate) {
        this.enqueueTranslation(segment);
        this.lastInterimText = segment.text;
        this.lastInterimTime = Date.now();
      }
    }
    
    // Progressive Summarizationç”¨ã«ãƒãƒƒãƒ•ã‚¡ãƒªãƒ³ã‚°
    if (segment.isFinal) {
      this.addToSummaryBuffer(segment.text);
      this.lastInterimText = ''; // ãƒªã‚»ãƒƒãƒˆ
    }
  }
  
  // ===== â‘¢ç¿»è¨³è¦æ±‚ + â‘£GPTå‡¦ç† + â‘¤å‡ºåŠ›æŠ½å‡º =====
  
  private enqueueTranslation(segment: TranscriptSegment): void {
    const task = async () => {
      const startTime = Date.now();
      let firstPaintTime = 0;
      
      try {
        // ğŸ”´ æ­£ã—ã„APIå‘¼ã³å‡ºã—æ–¹æ³•ï¼ˆtest-3min-complete.jsã§å‹•ä½œç¢ºèªæ¸ˆã¿ï¼‰
        // responses.stream ã‚’ä½¿ç”¨ï¼ˆchat.completions.createã§ã¯ãªã„ï¼‰
        // ã“ã‚ŒãŒGPT-5ç³»ãƒ¢ãƒ‡ãƒ«ã®æ­£ã—ã„å‘¼ã³æ–¹
        const stream = await this.openai.responses.stream({
          model: this.openaiConfig.models.translate,
          input: [
            { role: 'system', content: 'You are a professional translator. Translate English to natural Japanese. Output ONLY the Japanese translation without explanations / inner thoughts.' },
            { role: 'user', content: segment.text }
          ],
          max_output_tokens: this.openaiConfig.maxTokens.translate,
          reasoning: { effort: 'minimal' }
        });
        
        let translation = '';
        
        for await (const chunk of stream) {
          // test-3min-complete.js (517è¡Œç›®) ã«æº–æ‹ 
          if (chunk.type === 'response.output_text.delta' && chunk.delta) {
            const delta = chunk.delta;
            if (delta && !firstPaintTime) {
              firstPaintTime = Date.now() - startTime;
            }
            translation += delta;
            
            // â‘£Current Japaneseæ›´æ–°ï¼ˆã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ï¼‰
            // ä¸­é–“çµæœã‚‚æœ€çµ‚çµæœã‚‚ä¸¡æ–¹ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è¡¨ç¤º
            this.currentTranslation = translation;
            this.emit('currentTranslationUpdate', this.currentTranslation);
          }
        }
        
        const completeTime = Date.now() - startTime;
        
        // ç¿»è¨³å®Œäº†
        const result: Translation = {
          id: segment.id,
          original: segment.text,
          japanese: translation.trim(),
          timestamp: Date.now(),
          firstPaintMs: firstPaintTime,
          completeMs: completeTime
        };
        
        // â‘¥è¡¨ç¤ºæ®µéš
        if (segment.isFinal) {
          this.history.push(result);
          this.emit('translationComplete', result);
          
          // Current â†’ Historyç§»å‹•
          this.currentOriginal = '';
          this.currentTranslation = '';
        }
        
        // æˆåŠŸãƒ¡ãƒˆãƒªã‚¯ã‚¹
        console.log(`[ç¿»è¨³å®Œäº†] "${result.japanese.substring(0, 30)}..." (${completeTime}ms)`);
        
      } catch (error: any) {
        console.error('[UnifiedPipeline] Translation error:', error);
        console.error('[UnifiedPipeline] Error details:', {
          message: error.message,
          code: error.code,
          status: error.status,
          response: error.response?.data
        });
        this.emit('error', { 
          stage: 'translation', 
          error: error.message || String(error) 
        });
      }
    };
    
    this.translationQueue.push(task);
    this.processTranslationQueue();
  }
  
  private async processTranslationQueue(): Promise<void> {
    while (this.activeTranslations < this.maxConcurrency && this.translationQueue.length > 0) {
      const task = this.translationQueue.shift();
      if (task) {
        this.activeTranslations++;
        task().finally(() => {
          this.activeTranslations--;
          this.processTranslationQueue();
        });
      }
    }
  }
  
  // ===== Progressive Summarization (â‘¤â‘¥) =====
  
  private addToSummaryBuffer(text: string): void {
    this.summaryBuffer.push(text);
    this.summaryWordCount += text.split(' ').length;
    
    // é–¾å€¤ãƒã‚§ãƒƒã‚¯
    if (this.currentThresholdIndex < this.summaryThresholds.length) {
      const threshold = this.summaryThresholds[this.currentThresholdIndex];
      
      if (this.summaryWordCount >= threshold) {
        this.generateSummary();
        this.currentThresholdIndex++;
      }
    } else {
      // æœ€å¤§é–¾å€¤å¾Œã¯+800èªã”ã¨
      if (this.summaryWordCount >= this.summaryThresholds[2] + 800) {
        this.generateSummary();
        this.summaryWordCount = this.summaryThresholds[2]; // ãƒªã‚»ãƒƒãƒˆ
      }
    }
  }
  
  private async generateSummary(): Promise<void> {
    const text = this.summaryBuffer.join(' ');
    const startTime = Date.now();
    
    try {
      // â‘¤è‹±èªè¦ç´„ç”Ÿæˆ
      const englishResponse = await this.openai.chat.completions.create({
        model: this.openaiConfig.models.summary,
        messages: [
          { role: 'system', content: 'Summarize the lecture content in 3-5 bullet points.' },
          { role: 'user', content: text }
        ],
        max_tokens: this.openaiConfig.maxTokens.summary
      });
      
      const englishSummary = englishResponse.choices[0].message.content || '';
      
      // â‘¥æ—¥æœ¬èªè¦ç´„ç¿»è¨³
      const japaneseResponse = await this.openai.chat.completions.create({
        model: this.openaiConfig.models.summaryTranslate,
        messages: [
          { role: 'system', content: 'Translate to Japanese.' },
          { role: 'user', content: englishSummary }
        ],
        max_tokens: this.openaiConfig.maxTokens.summary
      });
      
      const japaneseSummary = japaneseResponse.choices[0].message.content || '';
      
      const summary: Summary = {
        id: `sum_${Date.now()}`,
        english: englishSummary,
        japanese: japaneseSummary,
        wordCount: this.summaryWordCount,
        timestamp: Date.now(),
        timeRange: {
          start: startTime,
          end: Date.now()
        }
      };
      
      this.summaries.push(summary);
      this.emit('summaryGenerated', summary);
      
      // ãƒãƒƒãƒ•ã‚¡ã‚¯ãƒªã‚¢
      this.summaryBuffer = [];
      
    } catch (error) {
      console.error('[UnifiedPipeline] Summary error:', error);
      this.emit('error', { stage: 'summary', error });
    }
  }
  
  // ===== â‘¦â‘§ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ç¿»è¨³ =====
  
  async translateUserInput(text: string, fromLang = 'ja', toLang = 'en'): Promise<string> {
    try {
      const direction = fromLang === 'ja' ? 'Japanese to English' : 'English to Japanese';
      
      const response = await this.openai.chat.completions.create({
        model: this.openaiConfig.models.userTranslate,
        messages: [
          { role: 'system', content: `Translate ${direction}. Output only the translation.` },
          { role: 'user', content: text }
        ],
        max_tokens: this.openaiConfig.maxTokens.translate
      });
      
      const translation = response.choices[0].message.content || '';
      
      this.emit('userTranslation', {
        original: text,
        translation,
        fromLang,
        toLang,
        timestamp: Date.now()
      });
      
      return translation;
      
    } catch (error) {
      console.error('[UnifiedPipeline] User translation error:', error);
      throw error;
    }
  }
  
  // ===== æœ€çµ‚ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ =====
  
  private async generateFinalReport(): Promise<void> {
    try {
      const context = {
        translations: this.history,
        summaries: this.summaries,
        duration: Date.now() - (this.history[0]?.timestamp || Date.now())
      };
      
      const response = await this.openai.chat.completions.create({
        model: this.openaiConfig.models.report,
        messages: [
          {
            role: 'system',
            content: 'Generate a comprehensive report of the lecture session.'
          },
          {
            role: 'user',
            content: JSON.stringify(context)
          }
        ],
        max_tokens: this.openaiConfig.maxTokens.report
      });
      
      const report = response.choices[0].message.content || '';
      
      this.emit('finalReport', {
        report,
        vocabulary: this.vocabulary,
        timestamp: Date.now()
      });
      
    } catch (error) {
      console.error('[UnifiedPipeline] Report generation error:', error);
    }
  }
  
  // ===== çŠ¶æ…‹å–å¾— =====
  
  getState() {
    return {
      isRunning: this.isRunning,
      currentOriginal: this.currentOriginal,
      currentTranslation: this.currentTranslation,
      historyCount: this.history.length,
      summaryCount: this.summaries.length,
      queueLength: this.translationQueue.length,
      activeTranslations: this.activeTranslations
    };
  }
  
  getHistory(): Translation[] {
    return [...this.history];
  }
  
  getSummaries(): Summary[] {
    return [...this.summaries];
  }
  
  /** âœ… ãƒã‚¤ã‚¯/ä»»æ„ãƒãƒ£ãƒ³ã‚¯ï¼šRendererã‹ã‚‰ã® raw PCM16 ã‚’ãã®ã¾ã¾WSã¸é€ã‚‹ */
  public sendAudioChunk(chunk: Buffer): void {
    if (!this.isRunning || !this.ws || this.ws.readyState !== WebSocket.OPEN) return;
    try {
      this.ws.send(chunk);
    } catch (e) {
      this.emit('error', e);
    }
  }
}